{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n\n\nfiles = []\n\nfor filename in os.listdir(\"../input/donald-trumps-rallies\"):\n    \n    with open(\"../input/donald-trumps-rallies/\" + filename) as f:\n        files.append(f.read())","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_text = \" \".join(files[-3:])\ntrain_text = \" \".join(files[:-3])\n\nf = open(\"train_dataset.txt\", 'w')\nf.write(train_text)\nf.close()\n\nf = open(\"test_dataset.txt\", 'w')\nf.write(validation_text)\nf.close()","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Could be changed to other models\nmodel_name = \"gpt2-medium\"","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ntrain_path = 'train_dataset.txt'\ntest_path = 'test_dataset.txt'","execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/718 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0039d320a5946448164f162cbf63aad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"027c6b0ca74d4712896c4e149b70597e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fadb5d9cf5d74aedb9dbcc90b47ddd08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a7fe1e9db4a4ee189c75ac532397cc3"}},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import TextDataset,DataCollatorForLanguageModeling\n\ndef load_dataset(train_path,test_path,tokenizer):\n    train_dataset = TextDataset(\n          tokenizer=tokenizer,\n          file_path=train_path,\n          block_size=128)\n     \n    test_dataset = TextDataset(\n          tokenizer=tokenizer,\n          file_path=test_path,\n          block_size=128)   \n    \n    data_collator = DataCollatorForLanguageModeling(\n        tokenizer=tokenizer, mlm=False,\n    )\n    return train_dataset,test_dataset,data_collator\n\ntrain_dataset,test_dataset,data_collator = load_dataset(train_path,test_path,tokenizer)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import Trainer, TrainingArguments,AutoModelWithLMHead\n\nmodel = AutoModelWithLMHead.from_pretrained(model_name)\n\n\ntraining_args = TrainingArguments(\n    output_dir=\"./gpt2-trump\", #The output directory\n    overwrite_output_dir=True, #overwrite the content of the output directory\n    num_train_epochs=3, # number of training epochs\n    per_device_train_batch_size=16, # batch size for training\n    per_device_eval_batch_size=64,  # batch size for evaluation\n    eval_steps = 400, # Number of update steps between two evaluations.\n    save_steps=800, # after # steps model is saved \n    warmup_steps=500,# number of warmup steps for learning rate scheduler\n    )\n\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n)","execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f2154c3883140a6b9a864af3fa8fa73"}},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainer.train()","execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n        </style>\n      \n      <progress value='633' max='633' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [633/633 09:25, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>2.796303</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"TrainOutput(global_step=633, training_loss=2.7388785363750245)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainer.save_model()","execution_count":8,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}